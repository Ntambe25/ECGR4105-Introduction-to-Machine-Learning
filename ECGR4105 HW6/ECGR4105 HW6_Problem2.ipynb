{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cb174d4",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "For 1st Part, a Convolution Neural Network for all 10 classes in CIFAR-10 will be created. The fully connected layer will be adjusted at the end with respect to the number of output classes.The Network will be trained for 300 epochs. Training Time, Training Loss, and Evaluation Accuracy after 300 epochs will be reported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6933f3c8",
   "metadata": {},
   "source": [
    "## Problem 2, Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd884767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing Pytorch and Tensorflow\n",
    "import torch\n",
    "torch.version.__version__\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03e3bf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Importing/Downloading the CIFAR-10 DataSet\n",
    "from torchvision import datasets\n",
    "data_path = \"../data-unversioned/p1ch7/\"\n",
    "\n",
    "# Convertion of the PIL Images into PyTorch Tensors\n",
    "from torchvision import transforms\n",
    "\n",
    "tensor_cifar10 = datasets.CIFAR10(data_path, train = True, download = True,\n",
    "                                  transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                              transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                                                   (0.2470, 0.2435, 0.2616))]))\n",
    "tensor_cifar10_val = datasets.CIFAR10(data_path, train = False, download = True,\n",
    "                                      transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                                 transforms.Normalize((0.4942, 0.4851, 0.4404),\n",
    "                                                                      (0.2467, 0.2429, 0.2616))]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62b2d6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary Libraries for CNN \n",
    "import torch.nn.functional as F\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9a8fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Conv2d(3,16, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16,8, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Linear(8 * 8 * 8, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87a1ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "    self.act1 = nn.Tanh()\n",
    "    self.pool1 = nn.MaxPool2d(2)\n",
    "    self.conv2 = nn.Conv2d(16,8, kernel_size=3, padding=1)\n",
    "    self.act2 = nn.Tanh()\n",
    "    self.pool2 = nn.MaxPool2d(2)\n",
    "    self.fc1 = nn.Linear(8*8*8,32)\n",
    "    self.act3 = nn.Tanh()\n",
    "    self.fc2 = nn.Linear(32,10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.pool1(self.act1(self.conv1(x)))\n",
    "    out = self.pool2(self.act2(self.conv2(out)))\n",
    "    out = out.view(-1, 8*8*8)\n",
    "    out = self.act3(self.fc1(out))\n",
    "    out = self.fc2(out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18936cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Training Loop\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs +1):\n",
    "        loss_train = 0.0;\n",
    "        for imgs, labels in train_loader:\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "        if(epoch == 1 or epoch % 10 == 0):\n",
    "            print(\"{} Epoch {}, Training Loss {}\".format(datetime.datetime.now(), epoch, loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c395d896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-10 12:30:52.997731 Epoch 1, Training Loss 2.0543598640910194\n",
      "2022-12-10 12:36:13.546336 Epoch 10, Training Loss 1.1958040703288124\n",
      "2022-12-10 12:42:05.820028 Epoch 20, Training Loss 1.013959146292923\n",
      "2022-12-10 12:47:52.256805 Epoch 30, Training Loss 0.9064702283390953\n",
      "2022-12-10 12:53:40.274262 Epoch 40, Training Loss 0.843773039786712\n",
      "2022-12-10 12:59:23.852780 Epoch 50, Training Loss 0.8058790556152763\n",
      "2022-12-10 13:06:02.444425 Epoch 60, Training Loss 0.7749857910148933\n",
      "2022-12-10 13:12:38.107592 Epoch 70, Training Loss 0.747799181991526\n",
      "2022-12-10 13:18:37.942449 Epoch 80, Training Loss 0.729450122932034\n",
      "2022-12-10 13:24:24.360593 Epoch 90, Training Loss 0.7102556972933547\n",
      "2022-12-10 13:30:09.199887 Epoch 100, Training Loss 0.692855961754194\n",
      "2022-12-10 13:35:59.027673 Epoch 110, Training Loss 0.6802598592799033\n",
      "2022-12-10 13:41:46.741818 Epoch 120, Training Loss 0.6655139482920737\n",
      "2022-12-10 13:47:34.024318 Epoch 130, Training Loss 0.6543021775648722\n",
      "2022-12-10 13:53:21.466781 Epoch 140, Training Loss 0.6439662533419211\n",
      "2022-12-10 13:59:04.112835 Epoch 150, Training Loss 0.6318329172709104\n",
      "2022-12-10 14:04:56.799375 Epoch 160, Training Loss 0.6230715788005258\n",
      "2022-12-10 14:10:47.739658 Epoch 170, Training Loss 0.6139330036576142\n",
      "2022-12-10 14:16:35.295498 Epoch 180, Training Loss 0.6042161126194707\n",
      "2022-12-10 14:22:22.087639 Epoch 190, Training Loss 0.5965553151295923\n",
      "2022-12-10 14:28:04.738427 Epoch 200, Training Loss 0.5889834132417083\n",
      "2022-12-10 14:34:03.477936 Epoch 210, Training Loss 0.5814849533083494\n",
      "2022-12-10 14:39:49.490656 Epoch 220, Training Loss 0.5757385792253572\n",
      "2022-12-10 14:45:43.197263 Epoch 230, Training Loss 0.5696734457522097\n",
      "2022-12-10 14:51:42.880448 Epoch 240, Training Loss 0.5640115015342108\n",
      "2022-12-10 14:57:25.324668 Epoch 250, Training Loss 0.5567568042089263\n",
      "2022-12-10 15:03:09.319732 Epoch 260, Training Loss 0.5516662240180823\n",
      "2022-12-10 15:08:58.929021 Epoch 270, Training Loss 0.5466603650842481\n",
      "2022-12-10 15:14:42.541399 Epoch 280, Training Loss 0.542008890577442\n",
      "2022-12-10 15:20:21.216198 Epoch 290, Training Loss 0.5365391156786238\n",
      "2022-12-10 15:25:58.220588 Epoch 300, Training Loss 0.5346228527977034\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(tensor_cifar10, batch_size = 64, shuffle = True)\n",
    "\n",
    "# Training Data with Data Loader\n",
    "model = Net()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(n_epochs = 300, optimizer = optimizer, model = model, loss_fn = loss_fn, train_loader = train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec733890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.80\n",
      "Accuracy val: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Measuring the Accuracy of the Trained Model\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(tensor_cifar10_val, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in[(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim = 1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name, (correct/total)))\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e555ad",
   "metadata": {},
   "source": [
    "## Problem 2, Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4e74831",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Conv2d(3,16, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16,8, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(8,4, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Linear(4*4*4, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9619ac6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-10 17:27:34.303518 Epoch 1, Training Loss 2.0369032587846525\n",
      "2022-12-10 17:33:11.410521 Epoch 10, Training Loss 1.1831883990856082\n",
      "2022-12-10 17:38:58.658766 Epoch 20, Training Loss 1.0020822544232049\n",
      "2022-12-10 17:44:46.279317 Epoch 30, Training Loss 0.9225083262566716\n",
      "2022-12-10 17:50:37.155050 Epoch 40, Training Loss 0.8689730754669975\n",
      "2022-12-10 17:56:26.426281 Epoch 50, Training Loss 0.8279266221748899\n",
      "2022-12-10 18:02:13.856025 Epoch 60, Training Loss 0.7939400663003897\n",
      "2022-12-10 18:47:52.085517 Epoch 70, Training Loss 0.7667722842653694\n",
      "2022-12-10 18:57:10.743248 Epoch 80, Training Loss 0.742296373181026\n",
      "2022-12-10 19:06:35.121050 Epoch 90, Training Loss 0.7218191839011429\n",
      "2022-12-10 19:15:41.094067 Epoch 100, Training Loss 0.7036517176329328\n",
      "2022-12-10 19:24:34.005317 Epoch 110, Training Loss 0.6875542137019165\n",
      "2022-12-10 19:33:32.481298 Epoch 120, Training Loss 0.6743000709187345\n",
      "2022-12-10 19:42:39.400717 Epoch 130, Training Loss 0.6621979605739988\n",
      "2022-12-10 19:51:48.267684 Epoch 140, Training Loss 0.6476988485249717\n",
      "2022-12-10 20:00:59.772916 Epoch 150, Training Loss 0.6391252548340947\n",
      "2022-12-10 20:16:07.756059 Epoch 160, Training Loss 0.6286876555294028\n",
      "2022-12-10 20:26:04.678731 Epoch 170, Training Loss 0.6210060711483212\n",
      "2022-12-10 20:35:14.563382 Epoch 180, Training Loss 0.6108529501406433\n",
      "2022-12-10 21:21:20.926446 Epoch 190, Training Loss 0.602737217265017\n",
      "2022-12-10 21:27:21.879817 Epoch 200, Training Loss 0.5940131061064923\n",
      "2022-12-10 21:33:19.903793 Epoch 210, Training Loss 0.58668473789759\n",
      "2022-12-10 21:39:22.170207 Epoch 220, Training Loss 0.5804361770753665\n",
      "2022-12-10 21:45:20.222970 Epoch 230, Training Loss 0.5732532905800568\n",
      "2022-12-10 21:51:22.065037 Epoch 240, Training Loss 0.5674169273365794\n",
      "2022-12-10 21:57:20.419090 Epoch 250, Training Loss 0.5601439091860486\n",
      "2022-12-10 22:03:20.134953 Epoch 260, Training Loss 0.5552792291888191\n",
      "2022-12-10 22:09:17.313592 Epoch 270, Training Loss 0.5520625307470026\n",
      "2022-12-10 22:15:15.571856 Epoch 280, Training Loss 0.5469319719030424\n",
      "2022-12-10 22:21:21.749799 Epoch 290, Training Loss 0.5420706868552796\n",
      "2022-12-10 22:27:21.906200 Epoch 300, Training Loss 0.5380271983421062\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(tensor_cifar10, batch_size = 64, shuffle = True)\n",
    "\n",
    "# Training Data with Data Loader\n",
    "model = Net()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(n_epochs = 300, optimizer = optimizer, model = model, loss_fn = loss_fn, train_loader = train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6abc98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.80\n",
      "Accuracy val: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Measuring the Accuracy of the Trained Model\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(tensor_cifar10_val, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in[(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim = 1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name, (correct/total)))\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e360bdb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
